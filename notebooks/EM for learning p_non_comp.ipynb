{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Stepwise EM algorithm below is based on these references:\n",
      "* http://blog.manfredas.com/expectation-maximization-tutorial/ (standard EM expained for a mixture of Bernoulli distibutions)\n",
      "* http://dawenl.github.io/files/em.pdf (similar to above)\n",
      "* https://hal.archives-ouvertes.fr/hal-00532968/document (description of stepwise EM)\n",
      "\n",
      "Other useful papers:\n",
      "* http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.4104&rep=rep1&type=pdf\n",
      "* http://www.aclweb.org/anthology/N/N09/N09-1069.pdf"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Stepwise EM test\n",
      "from random import random\n",
      "import numpy as np\n",
      "from collections import OrderedDict\n",
      "\n",
      "unobserved_p_non_comp = 0.3\n",
      "p_act_obs=1.0\n",
      "p_sanc=0.6\n",
      "p_pun=0.2\n",
      "p_viol_opt_dist = ('uniform', (1,1))\n",
      "\n",
      "data_len = 10000\n",
      "num_trials = 100\n",
      "num_M_steps_skipped = 5 # Only used if float(mini_batch_size*num_M_steps_skipped)/data_len <= 0.1\n",
      "\n",
      "def gen_data(num_data_points, p_non_comp, p_viol_opt_dist, p_act_obs, p_sanc, p_pun):\n",
      "  # What is a realistic distribution for p_viol_opt?\n",
      "  dist, params = p_viol_opt_dist\n",
      "  if dist == 'uniform':\n",
      "    lower, upper = params\n",
      "    lower = max(0, lower)\n",
      "    upper = min(1, upper)\n",
      "    p_viol_opt = lower + (upper-lower)*np.random.random(num_data_points)\n",
      "  else:\n",
      "    raise ValueError('Probability distribution {} is not implemented'.format(dist))\n",
      "  \n",
      "  data = []\n",
      "  for i in range(num_data_points):\n",
      "    if random() < p_non_comp:\n",
      "      if random() < p_viol_opt[i] * p_act_obs * p_sanc:\n",
      "        data += [1]\n",
      "      else:\n",
      "        data += [0]\n",
      "    else:\n",
      "      if random() < p_act_obs * p_pun:\n",
      "        data += [1]\n",
      "      else:\n",
      "        data += [0]\n",
      "  return (np.array(data), p_viol_opt)\n",
      "\n",
      "def gamma(n):\n",
      "    return n**(-0.6)\n",
      "\n",
      "# From http://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks-in-python\n",
      "def chunks(l, n):\n",
      "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
      "    for i in range(0, len(l), n):\n",
      "        yield l[i:i + n]\n",
      "        \n",
      "results_by_mini_batch_size = OrderedDict({})\n",
      "\n",
      "for mini_batch_size in [1, 5, 10, 20, 50, 100, 1000]:\n",
      "  results = []\n",
      "  for _ in range(num_trials):\n",
      "    (data, p_viol_opt) = gen_data(data_len, unobserved_p_non_comp, p_viol_opt_dist, p_act_obs, p_sanc, p_pun)\n",
      "    # Initial guesses for parameters\n",
      "    p_non_comp = 0.5\n",
      "    # Previous sufficient statistics for stepwise EM\n",
      "    z1 = 0 # Value not used and overwritten on first iteration\n",
      "    z2 = 0 # Value not used and overwritten on first iteration\n",
      "    for i,(chunk,p_viol_opt_chunk) in enumerate(zip(chunks(data, mini_batch_size), chunks(p_viol_opt, mini_batch_size))):\n",
      "      n = i+1\n",
      "      # E step\n",
      "      mu1 = p_viol_opt_chunk * p_act_obs * p_sanc # array\n",
      "      mu2 = p_act_obs * p_pun # singleton\n",
      "      pos_factor1 = mu1**chunk\n",
      "      neg_factor1 = (1.0-mu1)**(1-chunk)\n",
      "      pos_factor2 = mu2**chunk\n",
      "      neg_factor2 = (1.0-mu2)**(1-chunk)\n",
      "      num1 = p_non_comp * pos_factor1 * neg_factor1\n",
      "      num2 = (1.0 - p_non_comp) * pos_factor2 * neg_factor2\n",
      "      denom = num1 + num2\n",
      "      z1_new = num1/denom\n",
      "      z2_new = num2/denom\n",
      "      #print z1_new, z2_new\n",
      "      gamma_val = gamma(n)\n",
      "      z1 = (1 - gamma_val) * z1 + gamma_val * (np.sum(z1_new)/mini_batch_size)\n",
      "      z2 = (1 - gamma_val) * z2 + gamma_val * (np.sum(z2_new)/mini_batch_size)\n",
      "      #print z1,z2\n",
      "        # np.mean(z1, dtype=np.float64)\n",
      "      #p2 = (1 - gamma_val) * num2 + gamma_val * np.mean(z2)\n",
      "      #print 'z1: {}'.format(z1)\n",
      "      #print 'z2: {}'.format(z2)  \n",
      "      # M step\n",
      "      if float(mini_batch_size*num_M_steps_skipped)/data_len <= 0.1 and n > num_M_steps_skipped:\n",
      "        pass\n",
      "      else:\n",
      "        p_non_comp = z1\n",
      "        assert p_non_comp < 1\n",
      "\n",
      "    results += [p_non_comp]\n",
      "\n",
      "  results_by_mini_batch_size[mini_batch_size] = (np.mean(results), np.std(results))\n",
      "    \n",
      "print 'Mean and standard deviation for each mini-batch size (real p_non_comp={}, num_trials={})'.format(unobserved_p_non_comp, num_trials)\n",
      "print results_by_mini_batch_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean and standard deviation for each mini-batch size (real p_non_comp=0.3, num_trials=100)\n",
        "OrderedDict([(1, (0.41503146247902672, 0.22372710829286455)), (5, (0.41513571621968437, 0.091566163479216311)), (10, (0.41858712752985111, 0.069379896290697365)), (20, (0.41402160868211346, 0.049407686159634742)), (50, (0.4138062672097953, 0.031103629931466707)), (100, (0.4155345163843866, 0.022100442292434457)), (1000, (0.39114529805329851, 0.0065139666018273288))])\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}